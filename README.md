# âš–ï¸ Legal_Compliance_Text_Classification

## ğŸ“Œ Project Overview

This project focuses on **compliance classification of emails and disclosures** using **Large Language Models (LLMs)** with **Parameter-Efficient Fine-Tuning (PEFT)** and **Low-Rank Adaptation (LoRA)**.  

The dataset consists of **179 labeled examples** categorized into **four classes**:

- ğŸš« **CAN-SPAM Violation** â€“ Emails that violate CAN-SPAM Act requirements  
- âœ… **CAN-SPAM Compliant** â€“ Emails that comply with CAN-SPAM Act  
- ğŸ›¡ï¸ **CCPA Disclosure** â€“ Proper disclosures under the California Consumer Privacy Act  
- âŒ **Non-Disclosure** â€“ Inadequate or missing privacy notices  

---

## ğŸ”„ Pipeline

1. ğŸ§¹ **Data Preprocessing** â†’ Cleaning, formatting, preparing input (`dataset_preprocessing.ipynb`)  
2. ğŸ‹ï¸ **Model Training** â†’ Fine-tuning LLM with LoRA + PEFT (`lora-peft-compliance-classification.ipynb`)  
3. ğŸ“Š **Evaluation & Predictions** â†’ Testing on unseen data (`Test_Predictions.csv`)  

---

## ğŸ“Š Dataset Summary
**Total Examples**: 179  

- ğŸš« CAN-SPAM Violation: **54**  
- ğŸ›¡ï¸ CCPA Disclosure: **50**  
- âœ… CAN-SPAM Compliant: **40**  
- âŒ Non-Disclosure: **35**  

---

## ğŸ› ï¸ Approach

1. ğŸ”§ *Preprocessing*  
   - Standardized dataset  
   - Converted text + labels into machine-readable format  
   - Handled imbalance with stratified splitting  

2. ğŸ¤– *Model Fine-Tuning*  
   - Pre-trained transformer (GPT-2) with LoRA adapters  
   - Applied **PEFT (LoRA)** to reduce training cost  
   - Tuned LoRA rank & scaling for efficiency vs. accuracy  

3. ğŸ“ˆ *Evaluation*  
   - Tested on hold-out set  
   - Predictions saved in `Test_Predictions.csv`  
   - Metrics: **Accuracy, Precision, Recall, F1-score per class**  

4. ğŸš€ *Deployment Ready*  
   - Fine-tuned model can classify **new emails or disclosures** into four categories  

---

## ğŸ“Œ Results & Observations
- âš¡ **LoRA-PEFT** reduced GPU memory usage while maintaining strong performance  
- ğŸŒ Model generalizes well across compliance-related text despite limited dataset  
- âœ… Predictions show meaningful classification boundaries  

---

## ğŸ’¡ Recommendations
- ğŸ“ˆ **Expand Dataset** â†’ More compliance examples across industries/jurisdictions  
- âš–ï¸ **Class Balancing** â†’ Oversampling / augmentation for underrepresented classes  
- ğŸ¤ **Model Variants** â†’ Try **Legal-BERT**, **GPT-Legal**, or domain-specific models  
- ğŸ“Š **Evaluation Metrics** â†’ Use macro-F1 to handle imbalance  
- ğŸ”— **Deployment** â†’ Wrap with **FastAPI / Flask API** for compliance monitoring tools  

---

## ğŸ Conclusion
This project demonstrates how **LoRA + PEFT** can **efficiently fine-tune LLMs** for compliance classification, making it suitable for **real-world regulatory monitoring** and **legal text analysis** with **limited resources**.

---
